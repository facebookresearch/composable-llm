# Debugging configuration
cluster:
  compile_model: false  # You can compile on V100 or better GPU (I have P100, which do not allow for compilation)
  slurm:
    nodes: 1
    nb_gpus: 2        # use torchrun, or slurm, for multi-gpu runs
    time: 10          # job time in minutes
    signal_time: 60   # alert time in seconds

model:
  vocab_size: 32
  emb_dim: 64
  nb_heads: 2
  ffn_dim: 256
  nb_layers: 2

data:
  seq_len: 32
  batch_size: 16
  seed: 42
  gssm:
    # see `data.yaml` for other graph configuration
    nodes:
    - name: Z1
      state_dim: 4
      parents: [X]
      alpha: 1e3
    - name: Z2
      state_dim: 4
      alpha: 1e3
    - name: Z3
      state_dim: 4
      alpha: 1e3
    - name: Z4
      state_dim: 4
      parents: [X, Z3]
      alpha: 1e3
    - name: X
      state_dim: 32
      parents: [Z1, Z2, Z3, Z4]
      alpha: 1e-2

optim:
  steps: 100
  lr: 1e-2
  weight_decay: 0.1
  warmup: 10
  lr_min_ratio: 0

orchestration:
  name: debug 
  overwrite: true

  checkpoint:
    period: 20
    keep_only: 3

  logging:
    period: 1
    level: debug

  profiler:
    active: true
    wait: 1
    steps: -1

  utils:
    seed: 100

  wandb:
    active: false
    name: "me"
