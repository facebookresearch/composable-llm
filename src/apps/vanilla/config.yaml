launcher:
  name: vanilla
  overwrite: true
  log_dir: $HOME/vanilla

  script: src.apps.vanilla.train

  slurm:
    partition: scavenge
    mem: 16G
    nodes: 1
    nb_gpus: 8        # use torchrun, or slurm, for multi-gpu runs
    time: 10          # job time in minutes
    signal_time: 60   # alert time in seconds

run_config:
  cluster:
    compile_model: false

  data:
    root_dir: /checkpoint/vivc/datasets/smollm
    sources:
      smollm_python_edu: 12
      smollm_cosmopedia_v2: 15
      smollm_fineweb_edu_dedup: 65
    batch_size: 1
    prefetch_size: 4
    seq_len: 2048
    n_views: 2
    load_async: false
    tokenizer:
      name: tiktoken
      path: /checkpoint/vivc/tokenizer/llama3/tokenizer.model

  model:
    vocab_size: 32
    seq_len: 2048
    emb_dim: 64
    nb_heads: 2
    ffn_dim: 256
    nb_layers: 2

  optim:
    steps: 100
    lr: 1e-2
    weight_decay: 0.1
    warmup: 15
    lr_min_ratio: 0

  orchestration:
    utils:
      seed: 100

    checkpoint:
      period: 20
      keep_only: 3

    logging:
      period: 1
      level: debug
    wandb:
      active: false

    profiler:
      active: true
      wait: 1
      steps: -1

  eval:
    period: 0
    dataset_dir: /checkpoint/vivc/datasets/eval
    tasks: piqa
    generator:
      max_tokens: 2048
      # dtype: fp32

  # evaluation:
  #   period: 15
  #   asynchronous: false
  #   data:
  #     path: $HOME/data/composition/base/testset.h5
  #     n_data: 1_000
  #     batch_size: 16