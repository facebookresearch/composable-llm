# Debugging configuration
grid:
  data:
    path:
    - ${oc.env:HOME}/data/composition/base/trainset.h5
    - ${oc.env:HOME}/data/composition/sparse/trainset.h5
    - ${oc.env:HOME}/data/composition/low/trainset.h5
    n_data: [1_000, 10_000, 100_000]

monitor:
  name: debug_grid
  seed: 100
  overwrite: true

  logging:
    period: 1
    level: info
    wandb:
      active: false

  checkpoint:
    period: 20
    keep_only: 3

  profiler:
    active: true
    wait: 1
    steps: -1

cluster:
  compile_model: true  # You can compile on V100 or better GPU (I have P100, which do not allow for compilation)
  slurm:
    partition: scavenge
    mem: 64G
    nodes: 1
    nb_gpus: 8        # use torchrun, or slurm, for multi-gpu runs
    time: 30          # job time in minutes
    signal_time: 60   # alert time in seconds

model:
  vocab_size: 32
  emb_dim: 64
  nb_heads: 2
  ffn_dim: 256
  nb_layers: 2

data:
  path: ${oc.env:HOME}/data/composition/base/trainset.h5
  n_data: 10_000
  seq_len: 2048
  batch_size: 16
  seed: 42
  asynchronous: false

optim:
  steps: 500
  lr: 1e-2
  weight_decay: 0.1
  warmup: 10
  lr_min_ratio: 0
