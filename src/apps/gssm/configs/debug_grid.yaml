# Debugging configuration
launcher:
  name: debug_grid
  overwrite: true
  log_dir: $HOME/logs/debug_grid

  script: src.apps.gssm.train

  grid:
    data:
      path:
      - $HOME/data/composition/base/trainset.h5
      - $HOME/data/composition/sparse/trainset.h5
      - $HOME/data/composition/low/trainset.h5
      n_data: [1_000, 10_000, 100_000]

  slurm:
    partition: scavenge
    mem: 64G
    nodes: 1
    nb_gpus: 8        # use torchrun, or slurm, for multi-gpu runs
    time: 30          # job time in minutes
    signal_time: 60   # alert time in seconds

run_config:
  cluster:
    compile_model: true  # You can compile on V100 or better GPU (I have P100, which do not allow for compilation)

  model:
    vocab_size: 32
    seq_len: 2048
    emb_dim: 64
    nb_heads: 2
    ffn_dim: 256
    nb_layers: 2

  data:
    path: $HOME/data/composition/base/trainset.h5
    n_data: 10_000
    batch_size: 16
    seed: 42
    asynchronous: false

  optim:
    steps: 500
    lr: 1e-2
    weight_decay: 0.1
    warmup: 10
    lr_min_ratio: 0

  orchestration:
    utils:
      seed: 100

    logging:
      period: 1
      level: info
    wandb:
      active: false

    checkpoint:
      period: 20
      keep_only: 3

    profiler:
      active: true
      wait: 1
      steps: -1