"""
Utility to estimate difficulty levels of GSSM configurations.

License
-------
This source code is licensed under the terms specified in the `LICENSE` file,
located in the root directory of this repository.

@ 2025, Meta
"""

import json
import logging
import os
import zlib
from dataclasses import dataclass, field
from itertools import product
from pathlib import Path
from typing import Any

import numpy as np
import yaml

from nanollama.data.gssm import DataConfig, OnlineDataLoader, init_dataloader_state
from nanollama.utils import initialize_nested_object

logger = logging.getLogger("nanollama")


# -----------------------------------------------------------------------------
# Difficulty Estimation
# -----------------------------------------------------------------------------


def get_compression_ratio(batch: np.ndarray, level: int = 9) -> float:
    """
    Get the compression ratio of a sequence.
    Estimate the entropy of a sequence by compressing it with gzip.

    Parameters
    ----------
    seq:
        Sequence to estimate the entropy of.
    level:
        Compression level to use, by default 9.

    Returns
    -------
    Entropy estimate.
    """
    compressed_data = zlib.compress(batch.tobytes(), level=level)
    return len(compressed_data) / batch.size


def estimate_config_difficulty(config: DataConfig, level: int = 9) -> float:
    """
    Estimate the difficulty of a GSSM configuration by compressing sequences generated by it.

    Parameters
    ----------
    data_config:
        Configuration of the GSSM data loader.
    level:
        Compression level to use, by default 9.

    Returns
    -------
    Difficulty estimate.
    """
    # get batch
    state = init_dataloader_state(config)
    dataloader = OnlineDataLoader(config, state)
    batch = next(dataloader.generator)

    # estimate difficulty
    return get_compression_ratio(batch, level=level)


# -----------------------------------------------------------------------------
# Loop Over Configurations
# -----------------------------------------------------------------------------


@dataclass
class RangeValue:
    min: float = 1
    max: float = 1
    num: int = 1
    values: list[float] = field(init=False)

    def __post_init__(self):
        if self.num == 1:
            self.values = [self.min]
        self.values = np.logspace(np.log10(self.min), np.log10(self.max), num=self.num).tolist()


@dataclass
class DifficultyEstimationConfig:
    # dataloader related
    batch_size: int = 256
    seq_len: int = 2048
    seed: int = 42

    # generate configurations from base configuration and ranges for alpha values
    base_gssm: dict[str, Any] = field(default_factory=dict)
    alpha_X: RangeValue = field(default_factory=RangeValue)
    alpha_Z: RangeValue = field(default_factory=RangeValue)

    # saving path
    path: str = ""

    # compression level
    level: int = 9

    def __post_init__(self):
        if not self.path:
            self.path = str(Path.home() / "logs" / "difficulty_estimation.jsonl")
        else:
            self.path = os.path.expandvars(self.path)


def estimate_difficulty(config: DifficultyEstimationConfig) -> None:
    """
    Estimate the difficulty of a GSSM configuration by compressing sequences generated by it.

    Parameters
    ----------
    config:
        Configuration of the GSSM data loader.
    level:
        Compression level to use, by default 9.

    Returns
    -------
    Difficulty estimate.
    """
    gssm = config.base_gssm
    for node in gssm["nodes"]:
        node["alpha"] = 1

    data_keys = config.__dataclass_fields__.keys() & DataConfig.__dataclass_fields__.keys()
    data_config = initialize_nested_object(
        DataConfig,
        {"gssm": config.base_gssm}  # base gssm configuration
        | {key: getattr(config, key) for key in data_keys},  # dataloader configuration
    )
    difficulties = []

    # iterate over values of alpha_X and alpha_Z
    for alpha_X, alpha_Z in product(config.alpha_X.values, config.alpha_Z.values):
        # specialize base configuration accordingly
        for node in data_config.gssm.nodes:
            if node.name == "X":
                node.alpha = alpha_X
            else:
                node.alpha = alpha_Z

        logger.info(f"Estimating difficulty for alpha_X={alpha_X:.2e}, alpha_Z={alpha_Z:.2e}.")
        difficulty = estimate_config_difficulty(data_config, level=config.level)
        difficulties.append(
            {
                "difficulty": difficulty,
                "alpha_X": alpha_X,
                "alpha_Z": alpha_Z,
            }
        )
        logger.info(f"Difficulty: {difficulty:.2f}")

        with open(config.path, "a") as f:
            print(json.dumps(difficulty), file=f, flush=True)


# -----------------------------------------------------------------------------
# Main functions
# -----------------------------------------------------------------------------


def main() -> None:
    logging.basicConfig(
        level=logging.INFO,
        format="[%(levelname)s] %(filename)s:%(lineno)d - %(message)s",
        handlers=[logging.StreamHandler()],
    )

    yaml_config = """
    seq_len: 2048
    seed: 42
    batch_size: 100
    alpha_X:
        num: 2
        min: 1e-3
        max: 1e-2
    alpha_Z:
        min: 1e-3
        max: 1e3
        num: 10
    base_gssm:
        nodes:
            - name: Z2
              state_dim: 256
              parents: []
            - name: Z1
              state_dim: 256
              parents: [Z2]
            - name: X
              state_dim: 32
              parents: [Z1]
    path: $HOME/logs/difficulty_estimation.jsonl
    """

    config = yaml.safe_load(yaml_config)
    config = initialize_nested_object(DifficultyEstimationConfig, config)
    estimate_difficulty(config)


if __name__ == "__main__":
    main()


SBATCH_CONFIG = """
#!/bin/bash

#SBATCH --job-name=difficulty_estimation
#SBATCH --output=logs/difficulty_estimation_%j.log
#SBATCH --error=logs/difficulty_estimation_%j.err
#SBATCH --time=12:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=16G
#SBATCH --gres=gpu:0
#SBATCH --partition=scavenge
#SBATCH --array=0-9
"""

# TODO: loop over configuration
# TODO: launch a job array
