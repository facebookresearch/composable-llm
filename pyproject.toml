[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "nanollama"
version = "0.0.0"
authors = [
  { name="Vivien Cabannes", email="vivien.cabannes@gmail.com" },
]
description = "Get started with LLMs on math tasks"
readme = "README.md"
requires-python = ">=3.9"
classifiers = [
  "Programming Language :: Python :: 3",
  "License :: OSI Approved :: MIT License",
  "Operating System :: OS Independent",
]
dependencies = [
  "h5py",           # file system
  "numpy",
  "pyaml",          # configuration
  "torch",
  "wandb",          # logging
]

[project.optional-dependencies]
dev = [
  "ruff",               # formatting
  "torch_tb_profiler",  # visualizing profiling trace with tensorboard
  "viztracer",          # visualizing profiling trace with perfetto
]

llm = [
  "sentencepiece",  # tokenizer
  "tiktoken",       # tokenizer
  "blobfile",       # tiktoken dependency
]

visu = [
  "ipykernel",          # jupyter notebooks
  "ipywidgets",         # jupyter widgets
  "matplotlib", 
  "nbformat",           # jupyter format
  "plotly",
]

mamba = [
  "causal_conv1d",
  "mamba_ssm",
]

[project.urls]
"Homepage" = "https://github.com/fairinternal/composable-llm/"
"Bug Tracker" = "https://github.com/fairinternal/composable-llm/issues"

[tool.setuptools.packages.find]
where = ["src"]
exclude = ["src.apps", "src.evals"]

[tool.ruff]
line-length = 120

[tool.ruff.lint]
select = [
  "E", "F", "W",  # Default rules
  "ANN001",       # Function arguments should annotate types
  "ANN201",       # Public function should annotate return type
  "B",            # Common bugs
  "DTZ",          # Timezone issues
  "I",            # Sort inputs
  "PLE",          # Common errors
  "RUF100",       # Remove unused noqa
  "UP",           # Modern syntax
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401"]