{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from cot.data import Parity, BinaryCopy, Copy\n",
    "from cot.config import RAW_DIR\n",
    "from cot.models import Transformer, TransformerConfig\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Problem = BinaryCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "seq_length = 20\n",
    "max_nb_data_per_len = 1000\n",
    "random = False\n",
    "split_probas_by_len =  [1, 1, 1, 1, .9, .8, .9, .3, .2]\n",
    "probas_by_len = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1]).astype(float)\n",
    "probas_by_len /= probas_by_len.sum()\n",
    "\n",
    "lengths = list(np.arange(len(split_probas_by_len)) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cot.data.data_processing:Sequences of length 1 done. Saved in /home/vivc/Code/llm/Compositionality/data/raw/binary_copy (2/2 split).\n",
      "INFO:cot.data.data_processing:Sequences of length 2 done. Saved in /home/vivc/Code/llm/Compositionality/data/raw/binary_copy (4/4 split).\n",
      "INFO:cot.data.data_processing:Sequences of length 3 done. Saved in /home/vivc/Code/llm/Compositionality/data/raw/binary_copy (8/8 split).\n",
      "INFO:cot.data.data_processing:Sequences of length 4 done. Saved in /home/vivc/Code/llm/Compositionality/data/raw/binary_copy (16/16 split).\n",
      "INFO:cot.data.data_processing:Sequences of length 5 done. Saved in /home/vivc/Code/llm/Compositionality/data/raw/binary_copy (28/32 split).\n",
      "INFO:cot.data.data_processing:Sequences of length 6 done. Saved in /home/vivc/Code/llm/Compositionality/data/raw/binary_copy (51/64 split).\n",
      "INFO:cot.data.data_processing:Sequences of length 7 done. Saved in /home/vivc/Code/llm/Compositionality/data/raw/binary_copy (115/128 split).\n",
      "INFO:cot.data.data_processing:Sequences of length 8 done. Saved in /home/vivc/Code/llm/Compositionality/data/raw/binary_copy (76/256 split).\n",
      "INFO:cot.data.data_processing:Sequences of length 9 done. Saved in /home/vivc/Code/llm/Compositionality/data/raw/binary_copy (102/512 split).\n",
      "INFO:cot.data.data_processing:Loading training data.\n",
      "INFO:cot.data.data_processing:Setting sampler.\n",
      "INFO:cot.data.data_processing:Loading test data for binary_copy problem.\n"
     ]
    }
   ],
   "source": [
    "if Problem.prefix == 'copy':\n",
    "    Problem(vocab_size=20)\n",
    "\n",
    "Problem.generate_datafiles(max_nb_data_per_len, split_probas_by_len, rng)\n",
    "\n",
    "trainset = Problem()\n",
    "trainset.set_as_trainset(lengths, probas_by_len)\n",
    "\n",
    "testset = Problem()\n",
    "testset.set_as_testset(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(trainset, batch_size=32, sampler=trainset.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[1].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformerConfig(\n",
    "    vocab_size=4,\n",
    "    emb_dim=128,\n",
    "    pos_emb=True,\n",
    "    seq_len=20,\n",
    "    emb_dropout=0.1,\n",
    "    n_head=2,\n",
    "    n_layer=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embeddings): Embedding(\n",
      "    (token_emb): Embedding(4, 128)\n",
      "    (pos_emb): Embedding(20, 128)\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-1): 2 x TransformerBlock(\n",
      "      (norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): SelfAttention(\n",
      "        (qkv_mat): Linear(in_features=128, out_features=384, bias=False)\n",
      "        (output): Linear(in_features=128, out_features=128, bias=False)\n",
      "      )\n",
      "      (norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForward(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (output): Linear(in_features=128, out_features=4, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivc/Code/conda/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 10.217584311962128\n",
      "Loss: 7.802834510803223\n",
      "Loss: 6.353094637393951\n",
      "Loss: 5.898797899484634\n",
      "Loss: 5.46126389503479\n",
      "Loss: 5.370787471532822\n",
      "Loss: 5.105739146471024\n",
      "Loss: 4.880185544490814\n",
      "Loss: 4.755508065223694\n",
      "Loss: 4.687484264373779\n",
      "Loss: 4.442636847496033\n",
      "Loss: 4.120648562908173\n",
      "Loss: 4.088984429836273\n",
      "Loss: 3.8568408489227295\n",
      "Loss: 3.941498562693596\n",
      "Loss: 3.887954920530319\n",
      "Loss: 3.7642501294612885\n",
      "Loss: 3.720744490623474\n",
      "Loss: 3.5997921526432037\n",
      "Loss: 3.53359092772007\n",
      "Loss: 3.4738723188638687\n",
      "Loss: 3.665855199098587\n",
      "Loss: 3.5462906509637833\n",
      "Loss: 3.47406467795372\n",
      "Loss: 3.575624018907547\n",
      "Loss: 3.4897633641958237\n",
      "Loss: 3.577207922935486\n",
      "Loss: 3.447888672351837\n",
      "Loss: 3.4478889852762222\n",
      "Loss: 3.4787664711475372\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Transformer(config)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "losses = []\n",
    "test_losses = []\n",
    "\n",
    "n_epochs = 30\n",
    "model.train()\n",
    "for _ in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for sequence in loader:\n",
    "        # deal with EoS token being represented as -1\n",
    "        sequence += 1\n",
    "        sequence = sequence.to(device=device, dtype=torch.long)\n",
    "\n",
    "        inputs = sequence[:, :-1]\n",
    "        targets = sequence[:, 1:]\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.reshape(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    losses.append(total_loss)\n",
    "    print(f'Loss: {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1,  1,  0, -1,  0, -1,  1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 0,  0,  0,  0, -1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 0,  1, -1, -1, -1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 1,  0, -1, -1,  1,  1,  1,  1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [-1,  0,  1,  0,  0, -1,  0,  2,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 0,  1,  0, -1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [-1,  0,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 0,  1,  1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [-1, -1,  0,  0, -1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 0, -1, -1, -1, -1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 1, -1, -1,  1,  0,  0,  2,  2,  6,  0,  0,  0, -1,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 0, -1, -1,  0,  1,  0,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [-1,  0,  0, -1,  0,  0,  0,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [-1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 0,  0,  0, -1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [ 1,  0,  1, -1,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0]])\n"
     ]
    }
   ],
   "source": [
    "tmp = logits.argmax(-1) - targets\n",
    "tmp[targets == 3] = 6\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
